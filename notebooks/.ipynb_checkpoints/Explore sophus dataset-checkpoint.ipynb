{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the sophus dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load the data for each dataset from matfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_data = sio.loadmat(\"../data/data-sophus/X1_data.mat\")\n",
    "X2_data = sio.loadmat(\"../data/data-sophus/X2_data.mat\")\n",
    "X3_data = sio.loadmat(\"../data/data-sophus/X3_data.mat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a DataFrame for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.DataFrame(X1_data[\"X1_data\"])\n",
    "X2 = pd.DataFrame(X2_data[\"X2_data\"])\n",
    "X3 = pd.DataFrame(X3_data[\"X3_data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_labels = sio.loadmat(\"../data/data-sophus/X1_label.mat\")\n",
    "X2_labels = sio.loadmat(\"../data/data-sophus/X2_label.mat\")\n",
    "X3_labels = sio.loadmat(\"../data/data-sophus/X3_label.mat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the formating of the sample IDs so that all the datasets have the same format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we are only looking at the \"Sample ID\" labels. We want to compare these to make sure that the samples match up between datasets.\n",
    "The \"Samples ID\" labels are formated different for X1 than for X2 and X3, so we have to fix this before we can compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_sample_ID = []\n",
    "for l in X1_labels[\"X1_label\"][0,0]:\n",
    "    padded = f\"{int(l):07d}\"\n",
    "    with_dashes = \"-\".join([padded[:3],padded[3],padded[4:6],padded[6]])\n",
    "    X1_sample_ID.append(with_dashes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the sample IDs to make sure the samples match up between datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All samples have matching IDs\n"
     ]
    }
   ],
   "source": [
    "error_count = 0\n",
    "for l1,l2,l3 in zip(X1_sample_ID,X2_labels[\"X2_label\"][0,1],X3_labels[\"X3_label\"][0,1]):\n",
    "    if (l1 != l2) or (l2 != l3):\n",
    "        print(f\"Sample IDs {l1}, {l2} and {l3} does not match\")\n",
    "        error_count += 1\n",
    "if error_count > 0:\n",
    "    print(f\"{error_count} samples did not have maching IDs\")\n",
    "else:\n",
    "    print(\"All samples have matching IDs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make sure that all the sample IDs are unique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X1_sample_ID) == len(set(X1_sample_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the sample IDs as row labels for the dataframe\n",
    "Because the sample IDs are a unique identifier for each sample, we can use them as labels for the sample axis in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.set_axis(X1_sample_ID, inplace=True)\n",
    "X2.set_axis(X2_labels[\"X2_label\"][0,1], inplace=True)\n",
    "X3.set_axis(X3_labels[\"X3_label\"][0,1], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_classes = sio.loadmat(\"../data/data-sophus/X1_class.mat\")\n",
    "X2_classes = sio.loadmat(\"../data/data-sophus/X2_class.mat\")\n",
    "X3_classes = sio.loadmat(\"../data/data-sophus/X3_class.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 9)\n",
      "(2, 7)\n",
      "(2, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X1_classes[\"X1_class\"].shape)\n",
    "print(X2_classes[\"X2_class\"].shape)\n",
    "print(X3_classes[\"X3_class\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we will only look at the \"Diet\" class, which is class 7 in all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_diet = X1_classes[\"X1_class\"][0,6]\n",
    "X2_diet = X2_classes[\"X2_class\"][0,6]\n",
    "X3_diet = X3_classes[\"X3_class\"][0,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the sample diet classes to make sure the samples match up between datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All samples have matching diets\n"
     ]
    }
   ],
   "source": [
    "error_count = np.sum(X1_diet != X2_diet) + np.sum(X1_diet != X3_diet)\n",
    "if error_count > 0:\n",
    "    print(f\"{error_count} samples did not have maching diets\")\n",
    "else:\n",
    "    print(\"All samples have matching diets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All samples match for class 0\n",
      "All samples match for class 1\n",
      "All samples match for class 2\n",
      "All samples match for class 3\n",
      "All samples match for class 4\n",
      "All samples match for class 5\n",
      "All samples match for class 6\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    X1_class = X1_classes[\"X1_class\"][0,i]\n",
    "    X2_class = X2_classes[\"X2_class\"][0,i]\n",
    "    X3_class = X3_classes[\"X3_class\"][0,i]\n",
    "\n",
    "    error_count = np.sum(X1_class != X2_class) + np.sum(X1_class != X3_class)\n",
    "    if error_count > 0:\n",
    "        print(f\"{error_count} samples did not for class {i}\")\n",
    "    else:\n",
    "        print(f\"All samples match for class {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X1.to_csv(\"X1.csv\")\n",
    "#X2.to_csv(\"X2.csv\")\n",
    "#X3.to_csv(\"X3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_ID = X1_classes[\"X1_class\"][0,5]\n",
    "X2_ID = X2_classes[\"X2_class\"][0,5]\n",
    "X3_ID = X3_classes[\"X3_class\"][0,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 522  522 1142 1142 1672 1672 1282 1282 1382 1382 1722 1722  571  571\n",
      "  1101 1101 1482 1482  462  462  122  122  182  182  282  282 1452 1452\n",
      "  1431 1431  192  192  862  862 1851 1851  212  212  652  652 1801 1801\n",
      "  1761 1761  421 1502 1502  972  972  792  792 1802 1802 1782 1782  682\n",
      "   682  692  692 1742 1742 1662 1662 1712 1712  261  261  431  431 1212\n",
      "  1212  511  511 1342 1342 1221 1221 1741 1741  152  152 1214 1214 1572\n",
      "  1572  621  621  891  891 1322 1322 1172 1172 1721 1721   52   52  812\n",
      "   812 1561 1561  781  781  642  642  402  402  452  452  372  372  241\n",
      "   241 1362 1362 1552 1552 1182 1182 1232 1232 1092 1092  141  141  441\n",
      "   441  391  391  761  761 1492 1492 1582 1582  102  102  202  202 1162\n",
      "  1162  471  432  432  471 1252 1252  831  831  902  902 1042 1042  711\n",
      "   711 1642 1642 1222 1222  252  252  922  922 1202 1202 1072 1072  201\n",
      "   201  732  732 1151 1151  161  161 1062 1062   91   91  422  422   62\n",
      "    62  701  701  162  162 1372 1372  644  644 1141 1141 1871 1871  172\n",
      "   172  861  861  332  332  242  242 1332 1332  942  942 1292 1292  602\n",
      "   602  872  872 1071 1071  322  322 1521 1521   12   12  392  392  672\n",
      "   672  612  612 1091 1301 1301  362  362 1812 1812  882  882 1532 1532\n",
      "    71   71 1392 1392  352  352  491  491 1512 1512  952  952 1321 1321\n",
      "  1571 1571  791  791  222  222 1031 1031 1831 1831 1052 1052  982  982\n",
      "  1832 1832 1692 1692   92   92 1022 1022  852  852 1592 1592  662  662\n",
      "   154  154  661  661   72   72 1122 1122]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-56c7a1b850a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_sample_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mID_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX1_ID\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Idx\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mID_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX2_ID\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SampleID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "unique_IDs = np.unique(X1_ID)\n",
    "ID_dict = dict.fromkeys(unique_IDs)\n",
    "ID_dict = {k: {\"SampleID\":[], \"Idx\":[]} for k in unique_IDs}\n",
    "for i, sample_id in enumerate(X1_sample_ID):\n",
    "    print(X1_ID)\n",
    "    ID_dict[X1_ID[0,i]][\"Idx\"].append(i)\n",
    "    ID_dict[X2_ID[0,i]][\"SampleID\"].append(i)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
